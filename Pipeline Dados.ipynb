{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe responsável por armazenar os dados de folhosas e inmet por csv\n",
    "class AllDados:\n",
    "    def __init__(self, folhosas_csv, inmet_sp_csv, inmet_sorocaba_csv):\n",
    "        # Armazenando os dados da tabela csv em um DataFrame pandas\n",
    "        self.folhosas = pd.read_csv(folhosas_csv)\n",
    "        self.inmet_sp = pd.read_csv(inmet_sp_csv)\n",
    "        self.inmet_sorocaba = pd.read_csv(inmet_sorocaba_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe responsável por processar dados\n",
    "class ProcessadorDados:    \n",
    "    # Método responsável por limpar outliers\n",
    "    def clean_outliers(df):\n",
    "        df = df[(df != -9999).all(axis=1)]\n",
    "        df.loc[df.eq(-9999).any(axis=1)]\n",
    "        \n",
    "        return df\n",
    "\n",
    "    # Método responsável por agrupar dados por Data para descobrir a média diária de cada coluna\n",
    "    def daily_groupby(df):\n",
    "        df = df.groupby(['Data']).mean()\n",
    "        df.reset_index(inplace=True)\n",
    "\n",
    "        return df\n",
    "    \n",
    "    # Método responsável por extrair as datas de catálogo de produtos\n",
    "    def date_extract(df):\n",
    "        # Selecionando datas únicas\n",
    "        datas = df['Data'].unique()\n",
    "\n",
    "        # Encontrando a data anterior a uma semana do primeiro produto\n",
    "        primeira_data = pd.Timestamp(datas[0]) - dt.timedelta(days=7)\n",
    "\n",
    "        # Adicionando a primeira data as datas descobertas anteriormente\n",
    "        datas = pd.Series(datas)\n",
    "        datas = pd.concat([pd.Series([primeira_data]), datas], ignore_index=True)\n",
    "        \n",
    "        return datas\n",
    "\n",
    "    # Método responsável por agrupar dados pelos intervalos das datas de catálogo descobrir as médias de cada coluna\n",
    "    def weekly_groupby(inmet, datas):\n",
    "        # Criando um DataFrame para armazenar os dados do inmet\n",
    "        inmet_weekly = pd.DataFrame()\n",
    "\n",
    "        # Foreach para percorrer as datas identificadas e realizar os processamentos de dados\n",
    "        for i in range(len(datas) - 1):\n",
    "            intervalo_datas = inmet[(inmet['Data'] >= datas[i]) & (inmet['Data'] <= datas[i + 1])]\n",
    "\n",
    "            pivot = intervalo_datas[\n",
    "                ['Média Precipitação Total (mm)', 'Média Pressão Atmosférica (mB)', 'Média Temperatura do Ar (°C)',\n",
    "                 'Média Umidade Relativa do Ar (%)', 'Média Vento Velocidade (m/s)']].mean()\n",
    "            \n",
    "            pivot['Data'] = datas[i + 1]\n",
    "            \n",
    "            inmet_weekly = inmet_weekly.append(pivot, ignore_index=True)\n",
    "\n",
    "        return inmet_weekly\n",
    "    \n",
    "    # Método responsável por executar os processamentos de dados e gerar um novo inmet\n",
    "    def process_inmet(folhosas, inmet):\n",
    "        inmet = ProcessadorDados.clean_outliers(inmet)\n",
    "        inmet['Data'] = pd.to_datetime(inmet['Data'])\n",
    "\n",
    "        datas = ProcessadorDados.date_extract(folhosas)\n",
    "        inmet_processed = ProcessadorDados.weekly_groupby(inmet, datas)\n",
    "\n",
    "        return inmet_processed\n",
    "    \n",
    "    # Método responsável por formatar colunas DataFrame(arredondamento de casas decimais)\n",
    "    def format_columns(df):\n",
    "        df['Média Precipitação Total (mm)'] = df['Média Precipitação Total (mm)'].round(4)\n",
    "        df['Média Pressão Atmosférica (mB)'] = df['Média Pressão Atmosférica (mB)'].round(3)\n",
    "        df['Média Temperatura do Ar (°C)'] = df['Média Temperatura do Ar (°C)'].round(2)\n",
    "        df['Média Umidade Relativa do Ar (%)'] = df['Média Umidade Relativa do Ar (%)'].round(2)\n",
    "        df['Média Vento Velocidade (m/s)'] = df['Média Vento Velocidade (m/s)'].round(2)\n",
    "        df['Média Umidade Relativa do Ar (%)'] = df['Média Umidade Relativa do Ar (%)'].astype(str) + '%'\n",
    "\n",
    "        return df\n",
    "    \n",
    "    # Método responsável por fundir os dados de folhosas e inmet\n",
    "    def merge_folhosas_inmet(folhosas, inmet):\n",
    "        # Merge\n",
    "        folhosas_inmet = pd.merge(folhosas, inmet)\n",
    "\n",
    "        # Retorna DataFrame formatado\n",
    "        return ProcessadorDados.format_columns(folhosas_inmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe responsável por armazenar os dados de Mogi\n",
    "class Mogi():\n",
    "    def __init__(self, folhosas, inmet_sp):\n",
    "        self.folhosas = folhosas[folhosas['Região'] == \"Mogi das Cruzes\"]\n",
    "        self.inmet = ProcessadorDados.process_inmet(self.folhosas, inmet_sp)\n",
    "        self.folhosas_inmet = ProcessadorDados.merge_folhosas_inmet(self.folhosas, self.inmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe responsável por armazenar os dados de Ibiúna\n",
    "class Ibiuna():\n",
    "    def __init__(self, folhosas, inmet_sorocaba):\n",
    "        self.folhosas = folhosas[folhosas['Região'] == \"Ibiúna\"]\n",
    "        self.inmet = ProcessadorDados.process_inmet(self.folhosas, inmet_sorocaba)\n",
    "        self.folhosas_inmet = ProcessadorDados.merge_folhosas_inmet(self.folhosas, self.inmet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instância de AllDados (Salvando dados de folhosas, inmet_sp e inmet_sorocaba)\n",
    "all_dados = AllDados('Folhosas.csv', 'INMET\\\\SP_2013_2023.csv', 'INMET\\\\SOROCABA_2013_2023.csv')\n",
    "\n",
    "# Instância de Mogi (Salvando dados de mogi a partir de folhosas e inmet_sp)\n",
    "mogi = Mogi(all_dados.folhosas, all_dados.inmet_sp)\n",
    "\n",
    "# Instância de Ibiúna (Salvando dados de ibiuna a partir de folhosas e inmet_sorocaba)\n",
    "ibiuna = Ibiuna(all_dados.folhosas, all_dados.inmet_sorocaba)\n",
    "\n",
    "mogi.inmet[mogi.inmet.isna().any(axis=1)]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
